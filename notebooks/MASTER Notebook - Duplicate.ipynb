{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class='alert' style='background-color: #1c1a1e; color: #f5f4f0; padding:16px 26px; border-radius:20px; font-size:40px;'><B>MASTER Template</b> - [edit...] </div>\n",
    "<div style='margin:0px 26px; color:#1c1a1e; font-size:16px;'>\n",
    "<center>\n",
    "    <img src=\"https://github.com/janduplessis883/ai-medreview/blob/master/images/cute-robot4.png?raw=true\">\n",
    "</center> \n",
    "    \n",
    "### **Introduction**\n",
    "\n",
    "In this notebook, we will build a machine learning model to classify emotions from text data. We will utilize the power of transformers, specifically BERT (Bidirectional Encoder Representations from Transformers), to process and understand the text inputs.\n",
    "\n",
    "Transformers have revolutionized natural language processing (NLP) by providing state-of-the-art performance in various tasks, including text classification, sentiment analysis, and more. BERT, a model introduced by Google, leverages the transformer architecture to create rich contextual embeddings for text, making it highly effective for understanding the nuances of language.\n",
    "\n",
    "### Our goal is to:\n",
    "1. Load and preprocess the dataset.\n",
    "2.\tTokenize and vectorize the text input using BERT’s tokenizer.\n",
    "3.\tTrain a BERT model for emotion classification.\n",
    "4.\tEvaluate the model’s performance using metrics such as accuracy, confusion matrix, and ROC-AUC curve.\n",
    "5.\tVisualize the training process by plotting the loss and accuracy over time.\n",
    "\n",
    "### **Steps**\n",
    "1.\t**Load the Dataset**: We will begin by loading our dataset, which contains text data along with emotion labels.\n",
    "2.\t**Preprocess the Data**: Preprocessing will include encoding the labels and splitting the data into training and test sets.\n",
    "3.\t**Tokenize and Vectorize**: Using BERT’s tokenizer, we will convert the text data into a format suitable for the BERT model.\n",
    "4.\t**Train the Model**: We’ll fine-tune a pre-trained BERT model on our dataset to perform the emotion classification task.\n",
    "5.\t**Evaluate the Model**: After training, we’ll evaluate the model’s performance on the test set using various metrics.\n",
    "6.\t**Visualize Results**: Finally, we will plot the training loss and accuracy, confusion matrix, and ROC-AUC curve to understand how well our model performs.\n",
    "\n",
    "By the end of this notebook, you will have a trained BERT model capable of classifying emotions from text data and a clear understanding of its performance.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries & Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing default Libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import datetime \n",
    "import os \n",
    "\n",
    "from params import DATA_PATH\n",
    "\n",
    "pd.options.display.max_rows = 1000\n",
    "pd.options.display.max_columns = 1000\n",
    "\n",
    "# Hi-resolution Plots and Matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "%matplotlib inline\n",
    "\n",
    "# Set the maximum number of rows and columns to be displayed\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# \"magic commands\" to enable autoreload of your imported packages\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Vaccination type</th>\n",
       "      <th>Patient ID</th>\n",
       "      <th>Date of birth</th>\n",
       "      <th>Surname</th>\n",
       "      <th>Event date</th>\n",
       "      <th>Event done at ID</th>\n",
       "      <th>Patient Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Cholera 2</td>\n",
       "      <td>27861537</td>\n",
       "      <td>18-Nov-1992</td>\n",
       "      <td>Stanley</td>\n",
       "      <td>16-Mar-2015</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Measles/Mumps/Rubella 1</td>\n",
       "      <td>41183583</td>\n",
       "      <td>29-Mar-2013</td>\n",
       "      <td>Ferreira</td>\n",
       "      <td>22-Apr-2014</td>\n",
       "      <td>E87750</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Vaccination type  Patient ID Date of birth   Surname   Event date  \\\n",
       "0                Cholera 2    27861537   18-Nov-1992   Stanley  16-Mar-2015   \n",
       "1  Measles/Mumps/Rubella 1    41183583   29-Mar-2013  Ferreira  22-Apr-2014   \n",
       "\n",
       "  Event done at ID  Patient Count  \n",
       "0              NaN              1  \n",
       "1           E87750              1  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(f'{DATA_PATH}/dataset.csv')\n",
    "data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Exploratory Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
