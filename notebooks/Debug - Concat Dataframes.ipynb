{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b0a0c157",
   "metadata": {},
   "outputs": [],
   "source": [
    "from friendsfamilytest.utils import *\n",
    "from friendsfamilytest.params import *\n",
    "from friendsfamilytest.data import *\n",
    "from friendsfamilytest.sheethelper import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "209b4d48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[+] Friends & Family Test Analysis - MAKE DATA\n",
      "[🏁] FUCTION: load_google_sheet()\n",
      "[✔️] Completed: load_google_sheet() - Time taken: 2.85 seconds\n",
      "[🏁] FUCTION: load_local_data()\n",
      "[✔️] Completed: load_local_data() - Time taken: 0.01 seconds\n",
      "[*] New rows to process: 3\n",
      "[🏁] FUCTION: clean_text()\n",
      "[✔️] Completed: clean_text() - Time taken: 0.00 seconds\n",
      "[🏁] FUCTION: word_count()\n",
      "[✔️] Completed: word_count() - Time taken: 0.00 seconds\n",
      "[🏁] FUCTION: add_rating_score()\n",
      "[✔️] Completed: add_rating_score() - Time taken: 0.00 seconds\n",
      "[🏁] FUCTION: anonymize()\n",
      "[✔️] Completed: anonymize() - Time taken: 0.00 seconds\n",
      "[🏁] FUCTION: text_classification()\n",
      "[✔️] Completed: text_classification() - Time taken: 2.30 seconds\n",
      "[🏁] FUCTION: sentiment_analysis()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment-latest were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[✔️] Completed: sentiment_analysis() - Time taken: 2.26 seconds\n",
      "[🏁] FUCTION: improvement_classification()\n",
      "Batch processed: 1/3\n",
      "[✔️] Completed: improvement_classification() - Time taken: 14.20 seconds\n",
      "[🏁] FUCTION: textblob_sentiment()\n",
      "[✔️] Completed: textblob_sentiment() - Time taken: 0.03 seconds\n",
      "[🏁] FUCTION: concat_save_final_df()\n",
      "                   time              rating  ...    pos compound\n",
      "0   2023-07-13 15:28:22    Extremely likely  ...    NaN      NaN\n",
      "1   2023-07-13 15:29:16    Extremely likely  ...  0.516   0.4927\n",
      "2   2023-07-13 15:29:21    Extremely likely  ...  0.000   0.0000\n",
      "3   2023-07-13 15:30:10    Extremely likely  ...  0.508   0.4754\n",
      "4   2023-07-13 15:31:48    Extremely likely  ...  0.000  -0.6757\n",
      "..                  ...                 ...  ...    ...      ...\n",
      "633 2024-01-08 04:12:58  Extremely unlikely  ...  0.000  -0.4588\n",
      "634 2024-01-08 04:13:25  Extremely unlikely  ...  0.000  -0.3252\n",
      "635 2024-01-08 04:18:00    Extremely likely  ...  0.524   0.7650\n",
      "636 2024-01-08 05:03:04    Extremely likely  ...  0.416   0.5520\n",
      "637 2024-01-08 07:02:40    Extremely likely  ...  0.412   0.4215\n",
      "\n",
      "[638 rows x 18 columns]\n",
      "❌❌\n",
      "                   time                       rating  ...  pos compound\n",
      "638 2024-01-09 19:47:27  Neither likely nor unlikely  ...  0.0   -0.296\n",
      "639 2024-01-09 20:56:35             Extremely likely  ...  0.0    0.000\n",
      "640 2024-01-10 08:17:29                       Likely  ...  0.0    0.000\n",
      "\n",
      "[3 rows x 20 columns]\n",
      "[✔️] Completed: concat_save_final_df() - Time taken: 0.02 seconds\n"
     ]
    }
   ],
   "source": [
    "print(f\"{Fore.WHITE}{Back.BLACK}[+] Friends & Family Test Analysis - MAKE DATA\")\n",
    "\n",
    "# Load new data from Google Sheet\n",
    "raw_data = load_google_sheet()\n",
    "\n",
    "# Load local data.csv to dataframe\n",
    "processed_data = load_local_data()\n",
    "\n",
    "# Return new data for processing\n",
    "data = raw_data[~raw_data.index.isin(processed_data.index)]\n",
    "\n",
    "print(f\"{Fore.BLUE}[*] New rows to process: {data.shape[0]}\")\n",
    "if data.shape[0] != 0:\n",
    "    data = clean_text(data)  # clean text\n",
    "    data = word_count(data)  # word count\n",
    "    data = add_rating_score(data)\n",
    "    data = anonymize(data)\n",
    "    data = text_classification(data)\n",
    "    data = sentiment_analysis(data)\n",
    "    data = improvement_classification(\n",
    "        data, batch_size=16\n",
    "    )  # data = gpt3_improvement_classification(data)\n",
    "    data = textblob_sentiment(data)\n",
    "    concat_save_final_df(processed_data, data)\n",
    "    #do_git_merge()  # Push everything to GitHub\n",
    "else:\n",
    "    print(f\"{Fore.RED}[*] No New rows to add - terminated.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d00d4eca",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mdf_list\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "df_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a5f1a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "time\n",
    "rating\n",
    "free_text\n",
    "do_better\n",
    "free_text_len\n",
    "do_better_len\n",
    "rating_score\n",
    "classif\n",
    "classif_scores\n",
    "sentiment\n",
    "sentiment_score\n",
    "improvement_labels\n",
    "polarity\n",
    "subjectivity\n",
    "polarity\n",
    "subjectivity\n",
    "neg\n",
    "neu\n",
    "pos\n",
    "compound\n",
    "\n",
    "\n",
    "time\n",
    "rating\n",
    "free_text\n",
    "do_better\n",
    "free_text_len\n",
    "do_better_len\n",
    "rating_score\n",
    "classif\n",
    "classif_scores\n",
    "sentiment\n",
    "sentiment_score\n",
    "improvement_labels\n",
    "polarity\n",
    "subjectivity\n",
    "neg\n",
    "neu\n",
    "pos\n",
    "compound"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
